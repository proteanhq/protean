# Raising Events

!!! abstract "Applies to: DDD · CQRS · Event Sourcing"


An aggregate rarely exists in isolation - it's state changes often mean
that other parts of the system of the system have to sync up. In DDD, the
mechanism to accomplish this is through Domain Events.

## Delta Events

When an aggregate mutates, it also (preferably) raises one or more events
to record the state change in time, as well as propagate it within and beyond
the bounded context.

```python hl_lines="15-19"
--8<-- "guides/domain-behavior/002.py:16:35"
```

The generated events are collected in the mutated aggregate:

```shell hl_lines="8 12-15"
In [1]: account = Account(account_number="1234", balance=1000.0, overdraft_limit=50.0)

In [2]: account.withdraw(500.0)

In [3]: account.to_dict()
Out[3]: 
{'account_number': '1234',
 'balance': 500.0,
 'overdraft_limit': 50.0,
 'id': '37fc8d10-1209-41d2-a6fa-4f7312912212'}

In [4]: account._events
Out[4]: [<AccountWithdrawn: AccountWithdrawn object (
{'account_number': '1234',
 'amount': 500.0})>]
```

## Raising Events from Entities

Any entity in the aggregate cluster can raise events. But the events are
collected in the aggregate alone. Aggregates are also responisible for
consuming events and performing state changes on underlying entities, as we
will see in the future.

If the event is being generated by an entity, it can access the enclosing
aggregate's identity with the help of `_owner` property:

```python hl_lines="16 39"
{! docs_src/guides/domain-behavior/010.py !}
```

1. `self._owner` here is the owning `Patron` object.

## Dispatching Events {#stream-category}

These events are dispatched automatically to registered brokers when the
aggregate is persisted. We will explore this when we discuss repositories, but
you can also manually publish the events to the rest of the system with
`domain.publish()`.

Events are published to streams based on the aggregate's [stream category](../essentials/stream-categories.md). Each event is stored in a stream named `<domain>::<stream_category>-<aggregate_id>`, ensuring that all events for a specific aggregate instance are grouped together and can be processed in order.

Learn more about how stream categories organize message flows in the [Stream Categories](../essentials/stream-categories.md) guide.

<!-- FIXME Add link to repositories above -->

```shell hl_lines="11 16"
In [1]: order = Order(
   ...:         customer_id=1, premium_customer=True,
   ...:         items=[
   ...:             OrderItem(product_id=1, quantity=2, price=10.0),
   ...:             OrderItem(product_id=2, quantity=1, price=20.0),
   ...:         ]
   ...:     )

In [2]: order.confirm()

In [3]: order._events
Out[3]: 
[<OrderConfirmed: OrderConfirmed object ({'order_id': '149b5549-3903-459e-9127-731266372472', 'confirmed_at': '2024-06-10 22:53:25.827101+00:00'})>,
 <OrderDiscountApplied: OrderDiscountApplied object ({'order_id': '149b5549-3903-459e-9127-731266372472', 'customer_id': '1'})>]

In [4]: domain.publish(order._events)
```

## Event Sourced Aggregates: `raise_()` and `@apply` {#es-raise-apply}

For **event-sourced aggregates** (`is_event_sourced=True`), `raise_()`
does more than collect events — it automatically invokes the
corresponding `@apply` handler to mutate the aggregate's state in-place.
This makes `@apply` the **single source of truth** for all state
mutations, whether the aggregate is processing live commands or being
reconstructed from stored events.

```python
from protean import apply

@domain.aggregate(is_event_sourced=True)
class Order:
    customer_name: String(max_length=150, required=True)
    status: String(max_length=20, default="PENDING")

    @classmethod
    def place(cls, customer_name):
        order = cls._create_new()
        order.raise_(OrderPlaced(
            order_id=str(order.id),
            customer_name=customer_name,
        ))
        return order

    def confirm(self):
        self.raise_(OrderConfirmed(order_id=self.id))

    @apply
    def when_placed(self, event: OrderPlaced):
        self.customer_name = event.customer_name
        self.status = "PENDING"

    @apply
    def when_confirmed(self, event: OrderConfirmed):
        self.status = "CONFIRMED"
```

Key points for ES aggregates:

- Business methods **only raise events** — they never mutate state
  directly. The `@apply` handler does the mutation.
- `raise_()` wraps the `@apply` call inside `atomic_change()`, so
  **invariants are checked** before and after the state change.
- Every event raised **must** have a corresponding `@apply` handler.
  Raising an event without one throws `NotImplementedError`.
- Factory methods use `_create_new()` to create a blank aggregate
  with identity. The creation event's `@apply` handler populates
  all remaining state.

!!! note
    For standard (non-ES) aggregates, `raise_()` only collects
    events — it does not call `@apply` handlers. State is mutated
    directly in the business method, and `@apply` is not used.

## Fact Events

[Fact events](../domain-definition/events.md#fact-events) are automatically
generated by Protean.

The event name is of the format
`<AggregateName>FactEvent`, and the stream name will be
`<stream_category>-fact-<aggregate_id>`, where `stream_category` is the aggregate's [stream category](../essentials/stream-categories.md).

```python hl_lines="10 40 42"
{! docs_src/guides/domain-definition/events/003.py!}
```

The fact event for `User` aggregate in the above example is `UserFactEvent`
and the output stream is `user-fact-e97cef08-f11d-43eb-8a69-251a0828bbff`
